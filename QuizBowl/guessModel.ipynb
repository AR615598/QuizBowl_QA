{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, load_dataset, DatasetDict\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast\n",
    "import contextGenerator\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch\n",
    "import re\n",
    "import evaluate\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "model = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "contextGen = contextGenerator.LuceneRetrieval()\n",
    "try:\n",
    "    ds = load_from_disk('../res/data/qanta')\n",
    "except:\n",
    "    ds = load_dataset(\"community-datasets/qanta\", \"mode=first,char_skip=25\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data \n",
    "Given how BERT is a extractive model it will attempt to highlight its prediction in the provided context. In other words our task is to fine tune the model to predict the start and end positions of the answer in the context.  \n",
    "#### 1. Retreive context\n",
    "For each question we will need a relevent document where the answer may exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96221/96221 [4:18:24<00:00,  6.21 examples/s]     \n",
      "Map: 100%|██████████| 16706/16706 [14:50<00:00, 18.76 examples/s]\n",
      "Map: 100%|██████████| 1055/1055 [01:13<00:00, 14.31 examples/s]\n",
      "Map: 100%|██████████| 1161/1161 [01:21<00:00, 14.30 examples/s]\n",
      "Map: 100%|██████████| 2151/2151 [02:44<00:00, 13.05 examples/s]\n",
      "Map: 100%|██████████| 1953/1953 [02:21<00:00, 13.76 examples/s]\n",
      "Map: 100%|██████████| 1145/1145 [01:07<00:00, 17.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {'context':  contextGen(x['full_question'], 1)[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the start and end postions\n",
    "The contexts and questions are just strings to so we need to find the positions for the answers in the context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96221/96221 [00:18<00:00, 5223.65 examples/s]\n",
      "Map: 100%|██████████| 16706/16706 [00:03<00:00, 5426.48 examples/s]\n",
      "Map: 100%|██████████| 1055/1055 [00:00<00:00, 5698.17 examples/s]\n",
      "Map: 100%|██████████| 1161/1161 [00:00<00:00, 3495.97 examples/s]\n",
      "Map: 100%|██████████| 2151/2151 [00:00<00:00, 5880.18 examples/s]\n",
      "Map: 100%|██████████| 1953/1953 [00:00<00:00, 5915.87 examples/s]\n",
      "Map: 100%|██████████| 1145/1145 [00:00<00:00, 3488.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {'char_pos':  utils.term_char_index(x['answer'], x['context']['contents'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize context/question pair and find the token positions\n",
    "Ensure the context comes first in the pair to align the character index with the token index. BERT limits the combined token count of context and question to 512. Since the context is capped at 400 words, this won’t cause issues, but we’ll use padding and truncation for consistency and edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96221/96221 [02:51<00:00, 561.98 examples/s]\n",
      "Map: 100%|██████████| 16706/16706 [00:29<00:00, 559.08 examples/s]\n",
      "Map: 100%|██████████| 1055/1055 [00:01<00:00, 540.50 examples/s]\n",
      "Map: 100%|██████████| 1161/1161 [00:02<00:00, 472.54 examples/s]\n",
      "Map: 100%|██████████| 2151/2151 [00:03<00:00, 538.36 examples/s]\n",
      "Map: 100%|██████████| 1953/1953 [00:03<00:00, 542.76 examples/s]\n",
      "Map: 100%|██████████| 1145/1145 [00:01<00:00, 578.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "unpack = lambda x, y, z: {\"start_positions\": x, \"end_positions\": y, \"encodings\": z}\n",
    "\n",
    "def tokenize_row(row: dict, tokenizer):\n",
    "    try: \n",
    "        encoding =  tokenizer(\n",
    "            text = row['context']['contents'], \n",
    "            text_pair = row['full_question'], \n",
    "            padding = 'max_length', \n",
    "            truncation = 'only_first', \n",
    "            max_length = 512, \n",
    "            return_tensors = 'pt', \n",
    "            padding_side = 'right',\n",
    "            return_length = True\n",
    "            )\n",
    "    except:\n",
    "        cleaned = utils.clean_text(row['full_question'])\n",
    "        encoding =  tokenizer(\n",
    "            text = row['context']['contents'], \n",
    "            text_pair = cleaned, \n",
    "            padding = 'max_length', \n",
    "            truncation = 'only_first', \n",
    "            max_length = 512, \n",
    "            return_tensors = 'pt', \n",
    "            padding_side = 'right',\n",
    "            return_length = True\n",
    "            )\n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "    # Convert the dictionary to a BatchEncoding object\n",
    "    for (x, y) in row['char_pos']:\n",
    "        start_pos.append(encoding.char_to_token(x))\n",
    "        end_pos.append(encoding.char_to_token(y - 1))\n",
    "    return start_pos, end_pos, encoding\n",
    "\n",
    "\n",
    "\n",
    "ds = ds.map(lambda x: unpack(*tokenize_row(x, tokenizer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify consistent length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.decode(ds[0]['encodings'][\"input_ids\"][0][ds[0]['start_positions'][0]:ds[0]['end_positions'][0]+1], skip_special_tokens=True)\n",
    "splits = ['guesstrain', 'guessdev', 'guesstrain']\n",
    "count = []\n",
    "\n",
    "for y in splits:\n",
    "    for x in ds[y]:\n",
    "        if x['encodings']['length'][0] != 512:\n",
    "            count.append((x, y))\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (4/4 shards): 100%|██████████| 96221/96221 [00:00<00:00, 109545.66 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1055/1055 [00:00<00:00, 110052.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2151/2151 [00:00<00:00, 119300.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "guessTrain = DatasetDict({\n",
    "    'train': ds['guesstrain'],\n",
    "    'val': ds['guessdev'],\n",
    "    'test': ds['guesstest'],\n",
    "\n",
    "})\n",
    "guessTrain = guessTrain.remove_columns(['qanta_id', 'proto_id', 'qdb_id', 'dataset', 'text', 'char_idx', 'sentence_idx', 'tokenizations', 'fold']) \n",
    "\n",
    "guessTrain.save_to_disk('../res/data/guessTrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour-model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m---> 17\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m     processing_class\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     20\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"your-model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=guessTrain[\"train\"],\n",
    "    eval_dataset=guessTrain[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QBAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
